---
layout: post
title: YOLO系列（you only look once）
date: 2019-12-12
Author: Katherinaxxx
tags: [object detection]
excerpt: "目标检测发展史上重要篇章"
image: "/images/post/yolo/v1/loss.jpg"
comments: true
toc: true
---

<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

* any list
{:toc}

> [YOLOv1](https://arxiv.org/pdf/1506.02640.pdf)
[YOLOv3](https://pjreddie.com/media/files/papers/YOLOv3.pdf)

## YOLO系列
> [一文看懂YOLO v1](https://blog.csdn.net/litt1e/article/details/88814417)
[一文看懂YOLO v2](https://blog.csdn.net/litt1e/article/details/88852745)
[一文看懂YOLO v3](https://blog.csdn.net/litt1e/article/details/88907542)

## YOLOv1

开创one-stage先河，比起two-stage方法非常简洁。将提取候选框和分类回归统一到一个网络。

优点在于精简速度快

缺点：
YOLO对相互靠的很近的物体（挨在一起且中点都落在同一个格子上的情况），还有很小的群体 检测效果不好，这是因为一个网格中只预测了两个框，并且只属于一类。

测试图像中，当同一类物体出现的不常见的长宽比和其他情况时泛化能力偏弱。

由于损失函数的问题，定位误差是影响检测效果的主要原因，尤其是大小物体的处理上，还有待加强。


### 基本思路

将图片通过一个网络，得到x,y,w,h,confidence和class probability。也就是说，在训练阶段得到了中心点坐标、框的长宽、置信度，以及grid cell所属类别的概率。然后在inference阶段用NMS选出目标最佳的框。

### training

网络在GoogleNet的基础上，inception module改成1x1,3x3

1. pretraining预训练

前20层卷积在ImageNet上训练

2. 更改预训练模型用来做检测

一些细节：提高输入图片分辨率（据说效果会更好）；用leaky ReLU作为激活函数

**损失函数**

![loss](https://katherinaxxx.github.io/images/post/yolo/v1/loss.jpg#width-full){:height="90%" width="90%"}

关于损失函数有几点说明：
平方损失易于优化，它对定位错误的加权平均与分类误差相同，这可能不理想。同样，在每个图像中，许多网格单元都不包含任何对象。这会将这些单元格的“置信度”得分推向零，通常会超过确实包含对象的单元格的梯度。这可能会导致模型不稳定，从而导致训练在早期就出现分歧。
为了减少尺度大小带来的差异，将h、w开根号
由于不含目标的boxes占绝大多数，因此给他一个惩罚减小权重

### inference

论文中并没有详细介绍这一部分，用到的是NMS（非极大值抑制）
NMS方法并不复杂，其核心思想是：选择得分最高的作为输出，与该输出重叠的去掉，不断重复这一过程直到所有备选处理完。

![nms](https://katherinaxxx.github.io/images/post/yolo/v1/nms.jpg#width-full){:height="90%" width="90%"}

> [YOLO系列改进](https://blog.csdn.net/qq_18941713/article/details/90811882)

| YOLOv1  |  YOLOv2  |  YOLOv3  |
|  ----  | ----  | ----  | ----  |
| bbox对一个格子多个目标的预测能力很差 | 引入了anchor,且删除了yolo的全连接层，使用anchor预测bbox；etc| logistic替代softmax，来预测每个类别得分并使用一个阈值来对目标进行多标签预测；etc |
