---
layout: post
title: nlp领域技术
date: 2020-03-23
Author: Katherinaxxx
tags: [object detection]
excerpt: "技术、论文、代码、应用"
image: "/images/post/nlp/.jpg"
comments: true
toc: true
---

<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

* any list
{:toc}

## ELMo（2018）

ELMo以前主要word enbedding，比如word2vec，但是存在问题，因为形成的词嵌入都是固定的表示（静态），因而不能解决一词多义的问题。
ELMo同样映射成向量，但会根据上下文信息进行微调（动态），从而解决一词多义的问题。这是他的设计初衷。

ELMo框架：BiLSTM

## BERT（2019）

相比ELMo，BERT用transformer做框架，特征抽取的能力更强

## RoBERTa（2020）

BERT缺乏训练，RoBERTa使用更多的数据、batchs，在更长的序列上训练。此外还对BERT的两个预训练任务（MLM，NSP下个句子预测）进行了修改。

## ALBERT（2020）

在不影响模型效果的前提下，减少参数量
