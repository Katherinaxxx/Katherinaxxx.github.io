---
layout: post
title: 小物体目标检测---PGAN
date: 2019-11-12
Author: Katherinaxxx
tags: [GAN]
excerpt: "原始论文详解"
image: "/images/post/pgan/f1.jpg"
comments: true
toc: true
---

<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

* any list
{:toc}

>[PGAN论文]()

## PGAN

### 小物体目标检测难点

小物体的分辨率很小且存在噪声的影响，导致小物体目标检测有一定难度

### PGAN的解决思路

基于GAN的结构，生成器将小物体的低分辨率特征表示转化成类似大物体的高分辨率特征表示的版本；生成器由两部分组成，adversarial branch和perception branch

![f1](https://katherinaxxx.github.io/images/post/pgan/f1.jpg#width-full){:height="90%" width="90%"}

adversarial branch用来区分小物体的高分辨率特征和大物体的高分辨率特征，perception branch用于justifying the detection accuracy benefiting from the generated representation

#### 训练

![f2](https://katherinaxxx.github.io/images/post/pgan/f2.jpg#width-full){:height="90%" width="90%"}

先用大物体数据训练perception branch，然后小物体喂给G生成类似大物体高分辨率特征表示，最后训练D来区分生成的和大物体。


### PGAN结构

![f2](https://katherinaxxx.github.io/images/post/pgan/f2.jpg#width-full){:height="90%" width="90%"}

#### 生成器G

生成器并非直接学习将低分辨率特征表示转换到高分辨率特征表示的映射，因为低分辨率包含的数据不足。而是通过学习高分辨率特征表示与低分辨率特征表示的残差（差别），然后残差加上低分辨率特征表示后即可得到高分辨率特征表示。因此对vanilla GAN的损失做了残差的修改

![e1](https://katherinaxxx.github.io/images/post/pgan/e1.jpg#width-full){:height="90%" width="90%"}

训练时损失函数

![g](https://katherinaxxx.github.io/images/post/pgan/g.jpg#width-full){:height="90%" width="90%"}


#### 判别器D

判别器有两部分组成adversarial branch和perception branch，前者是用于区分生成的高分辨率特征表示和大物体的高分辨率特征表示，后者用于目标检测。二者共用前两个FC层，训练时判别器的损失由二者损失加权得到

#### adversarial branch

实际是真正意义上的判别器，训练时损失函数

![d](https://katherinaxxx.github.io/images/post/pgan/g.jpg#width-full){:height="90%" width="90%"}

#### perception branch

其损失其实就是目标检测分类和候选框回归的损失

![g](https://katherinaxxx.github.io/images/post/pgan/g.jpg#width-full){:height="90%" width="90%"}


### 实验

论文中实验用到的数据集有：
Tsinghua-Tencent 100K 真实交通信号数据集
Caltech 行人
实验的细节论文其实没有很详细，基本是在fast RCNN的框架下完成的，用到了已训练好的VGG，和在选取候选框时用到了RPN和ACF，等等。

实验结果详细见论文
