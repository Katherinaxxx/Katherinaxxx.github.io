---
layout: post
title: 超分问题---SRGAN
date: 2019-10-28
Author: Katherinaxxx
tags: [GAN]
excerpt: "论文、代码"
image: "/images/post/srgan/comapre1.jpg"
comments: true
toc: true
---

<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

* any list
{:toc}

>[SRGAN论文](http://openaccess.thecvf.com/content_cvpr_2017/papers/Ledig_Photo-Realistic_Single_Image_CVPR_2017_paper.pdf)

## SRGAN

基于GAN的生成在四倍放大下仍保留细节的超分图像的模型。以下是SRGAN生成的超分图片和真实高分辨图片的对比

![compare1](https://katherinaxxx.github.io/images/post/srgan/comapre1.jpg#width-full){:height="90%" width="90%"}

可以看出，由SRGAN生成的超分图片即使在四倍放大下也几乎很难与真实高分辨图片区分开来。

### 存在的问题

MSE、SNR、PSNR定义如下：

![msp](https://katherinaxxx.github.io/images/post/srgan/mse_snr_psnr.jpg#width-full){:height="90%" width="90%"}


**在此之前的超分模型（eg.CNN)** 大多用MSE作为损失。因此使得图像有较高信噪比（PSNR），这样就会导致确实高频细节，倍数放大后图像过于光滑。而SRGAN提出了perceptual loss来替代基于图像像素的MSE损失。

### SRGAN给出的解决

正如上文提到的，本文提出的perceptual loss是解决问题的关键，由cnotent loss和Adversarial loss两部分组成

![ploss](https://katherinaxxx.github.io/images/post/srgan/ploss.jpg#width-full){:height="90%" width="90%"}

1. cnotent loss

回顾原始MSE loss是一个光滑的损失，去掉了很多噪声，因而使得细节丢失。为了尽可能保留这些特征，且生成前后图像相似，本文认为图像的高维特征应要保持一致，因此提出用VGGNet的feature map

![vggloss](https://katherinaxxx.github.io/images/post/srgan/vggloss.jpg#width-full){:height="90%" width="90%"}

2. Adversarial loss

本文同样引入GAN这个生成模型，希望通过GAN能够生成图像尽可能保持高维流形从而保留其细节纹理，如下图所示

![nature](https://katherinaxxx.github.io/images/post/srgan/nature.jpg#width-full){:height="90%" width="90%"}

GAN的判别器的训练仍是希望能尽可能将生成图片与真实图片区分开，生成器则仍是尽量生成足以骗过判别器的图片。因此GAN的损失函数其实没有什么变化，生成器损失可以写成下面这种

![adloss](https://katherinaxxx.github.io/images/post/srgan/adloss.jpg#width-full){:height="90%" width="90%"}


### 实验

生成器和判别器的结构如下所示

![con](https://katherinaxxx.github.io/images/post/srgan/con.jpg#width-full){:height="90%" width="90%"}

本文认为PSNR和SSIM不是特别好的评价图像质量的指标，为了从人的感官评价，用MOS作为参考。SRGAN与其他方法对比结果如下

![mos](https://katherinaxxx.github.io/images/post/srgan/mos.jpg#width-full){:height="90%" width="90%"}

![compare](https://katherinaxxx.github.io/images/post/srgan/compare.jpg#width-full){:height="90%" width="90%"}

可见，SRGAN的MOS是最高的。

### 实现
