---
layout: post
title: 数据结构与算法
date: 2019-11-11
Author: Katherinaxxx
tags: [algorithm]
excerpt: "总览、时间复杂度"
image: "/images/pic08.jpg"
comments: true
toc: true
---
<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

>最近在学习数据结构与算法，以此记录学习过程，时长两个月，不定时更新。

* any list
{:toc}

## 总览


### 数据结构

>首先附上极客大学课程中给出的[参考脑图](https://naotu.baidu.com/file/b832f043e2ead159d584cca4efb19703?token=7a6a56eb2630548c)

![数据结构](https://katherinaxxx.github.io/images/post/algorithm1/数据结构.jpeg#width-full){:height="90%" width="90%"}


### 算法

>首先附上极客大学课程中给出的[参考脑图](https://naotu.baidu.com/file/0a53d3a5343bd86375f348b2831d3610?token=5ab1de1c90d5f3ec)

![算法](https://katherinaxxx.github.io/images/post/algorithm1/算法.jpeg#width-full){:height="90%" width="90%"}

## 时间复杂度和空间复杂度分析

### Big O notation

>详细可参考知乎上的[理解](https://www.zhihu.com/question/21387264)以及《算法导论》有定义和推导

$O(f(n))$代表上界，意为该算法的运行时间随数据量的增长所呈现出来的时间—数据量关系不会比$f(n)$更差。但$O(f(n))$并不代表该算法的时间—数据量关系恰好符合$f(n)$所表达出来的数量级；它只是个上界。

* O(1): constant complexity 常数复杂度
* O($logn$): logarithmic complexity 对数复杂度
* O(n): linear complexity 线性时间复杂度
* etc

*ps.* 不考虑系数，只看最高复杂度的运算

将不同时间复杂度与在不同n下绘制成图像

![compare](https://katherinaxxx.github.io/images/post/algorithm1/compare.jpg#width-full){:height="90%" width="90%"}

可以看到，n越大差别越大，因而优化代码（复杂度）在实际工程中可以节约巨大的资源。

#### 递归

递归代码分析算法复杂度可以用到主定理[Master Thorem](https://en.wikipedia.org/wiki/Master_theorem_(analysis_of_algorithms))，主要常用一下四种

![master](https://katherinaxxx.github.io/images/post/algorithm1/master-thorem.jpg#width-full){:height="90%" width="90%"}

#### 常用算法时间复杂度

|  算法   | 时间复杂度  |
|  ----  | ----  |
| 二叉树遍历-前序、中序、后序  | O(n) |
| 图的遍历  | O(n)  |
| 搜索算法-DFS、BFS | O(n) |
| 二分查找 | O(logn) |

对于二叉树遍历，可以根据主定理得到，也可以这样理解：不管是前序、中序、后序，每个节点会访问一次且仅访问一次，所以他的时间复杂度线性于二叉树节点总数n。
同理，图里面的节点n访问一次且仅访问一次。DFS、BFS也仅访问一次，n指的是搜索空间里的节点总数。

![o](https://katherinaxxx.github.io/images/post/algorithm1/o.jpg#width-full){:height="90%" width="90%"}

## 数组、链表、跳表

### 数组 array

#### 实现

计算机在内存中开辟连续的地址，每一个地址可以通过内存管理器访问。

![array](https://katherinaxxx.github.io/images/post/algorithm1/array.jpg#width-full){:height="60%" width="60%"}

#### 特性

访问时间快 ：O(1)
增删（群移操作）慢 ：平均O(n) 头尾O(1)


### 链表 linked list

在修改和增删操作比较频繁的情况下，数组并不好用。

#### 实现

![linkedlist](https://katherinaxxx.github.io/images/post/algorithm1/linkedlist.jpg#width-full){:height="90%" width="90%"}

如图，头指针叫head，尾指针叫tail。只有一个next叫单链表，如果还有往前指的叫双向链表，如果tail的next指向head则叫循环链表。

#### 特性

访问慢：平均O(n) 头尾O(1)
增删（修改next）快： O(1)

### 跳表 skip list

#### 实现/思想

**升维、空间换时间**

![skiplist](https://katherinaxxx.github.io/images/post/algorithm1/skiplist.jpg#width-full){:height="90%" width="90%"}

增加$log_2{n}$级索引

#### 时间复杂度、空间复杂度

第k级索引节点个数为$n/2^k$
假设h级索引，最高级索引2个节点。则$n/2^k=2$，解得$h=log_2{n}-1$。因此，时间复杂度为O(logn)。
假设每两个节点抽一个，则每层索引节点个数为：

$$\frac{n}{2}、\frac{n}{4}、\frac{n}{8}、...、4、2$$

因为收敛，所以累加计算

$$S_n=\frac{n}{2}+\frac{n}{4}+\frac{n}{8}+...+4+2$$

则

$$qS_n=\frac{n}{4}+\frac{n}{8}+\frac{n}{18}+...+2+2$$

两式相减得$(1-q)S_n=\frac{n}{2}-1$，故$S_n=n-2$
因此空间复杂度为O(n)。

### 工程应用

#### LRU

>参考[简书](https://www.jianshu.com/p/b1ab4a170c3c)

LRU（Least Recently Used）算法。假设缓存的大小固定，初始状态为空。每发生一次读内存操作，首先查找待读取的数据是否存在于缓存中，若是，则缓存命中，返回数据；若否，则缓存未命中，从内存中读取数据，并把该数据添加到缓存中。向缓存添加数据时，如果缓存已满，则需要删除访问时间最早的那条数据，这种更新缓存的方法就叫做LRU。

HashMap+双向链表。HashMap保证通过key访问数据的时间为O(1)，双向链表则按照访问时间的顺序依次穿过每个数据。

以[leetcode146. LRU缓存机制](https://leetcode-cn.com/problems/lru-cache/)为例，要求设计和实现一个LRU缓存机制。它应该支持以下操作： <font color="#000066">获取数据 get</font><br />和<font color="#000066">写入数据 put</font><br />

获取数据 get(key) - 如果密钥 (key) 存在于缓存中，则获取密钥的值（总是正数），否则返回 -1。
写入数据 put(key, value) - 如果密钥不存在，则写入其数据值。当缓存容量达到上限时，它应该在写入新数据之前删除最近最少使用的数据值，从而为新的数据值留出空间。

```python
    class ListNode:
        def __init__(self, key=None, value=None):
            self.key = key
            self.value = value
            self.prev = None
            self.next = None


    class LRUCache:
        def __init__(self, capacity: int):
            self.capacity = capacity
            self.hashmap = {}
            # 新建两个节点 head 和 tail
            self.head = ListNode()
            self.tail = ListNode()
            # 初始化链表为 head <-> tail
            self.head.next = self.tail
            self.tail.prev = self.head

        # 因为get与put操作都可能需要将双向链表中的某个节点移到末尾，所以定义一个方法
        def move_node_to_tail(self, key):
                # 先将哈希表key指向的节点拎出来，为了简洁起名node
                #      hashmap[key]                               hashmap[key]
                #           |                                          |
                #           V              -->                         V
                # prev <-> node <-> next         pre <-> next   ...   node
                node = self.hashmap[key]
                node.prev.next = node.next
                node.next.prev = node.prev
                # 之后将node插入到尾节点前
                #                 hashmap[key]                 hashmap[key]
                #                      |                            |
                #                      V        -->                 V
                # prev <-> tail  ...  node                prev <-> node <-> tail
                node.prev = self.tail.prev
                node.next = self.tail
                self.tail.prev.next = node
                self.tail.prev = node

        def get(self, key: int) -> int:
            if key in self.hashmap:
                # 如果已经在链表中了就把它移到末尾（变成最新访问的）
                self.move_node_to_tail(key)
            res = self.hashmap.get(key, -1)
            if res == -1:
                return res
            else:
                return res.value

        def put(self, key: int, value: int) -> None:
            if key in self.hashmap:
                # 如果key本身已经在哈希表中了就不需要在链表中加入新的节点
                # 但是需要更新字典该值对应节点的value
                self.hashmap[key].value = value
                # 之后将该节点移到末尾
                self.move_node_to_tail(key)
            else:
                if len(self.hashmap) == self.capacity:
                    # 去掉哈希表对应项
                    self.hashmap.pop(self.head.next.key)
                    # 去掉最久没有被访问过的节点，即头节点之后的节点
                    self.head.next = self.head.next.next
                    self.head.next.prev = self.head
                # 如果不在的话就插入到尾节点前
                new = ListNode(key, value)
                self.hashmap[key] = new
                new.prev = self.tail.prev
                new.next = self.tail
                self.tail.prev.next = new
                self.tail.prev = new
```

## 栈、队列、优先队列、双端队列

### 栈stack

先入后出
O(1) 增删
O(n) 查询

应用：最内到外or从外到内 两两匹配

### 队列

先进先出
O(1) 增删
O(n) 查询

### 双端队列deque

两端进出
O(1) 增删
O(n) 查询

    from collections import deque

### 优先队列priority queue

插入O(1)
取出O(logn) 按元素优先级取出
底层具体实现的数据结构较为多样和复杂：heap、bst（二叉搜索树）、treap
python [heapq](https://docs.python.org/2/library/heapq.html)

## 哈希表、映射、集合

### 哈希表 Hash Table

$$ key -(hash function)-> index - value $$

(少数出现) Hash collisions 用 拉链法
完美哈希： key通过hash function唯一对应index
查询、增删：平均O(1) （最差退化成链表O(n))

* java: map （key-value对 key不重复）；set（单个不重复元素集合）

* python： dict（specially，collections.defaultdict）；set


## 树、二叉树、二叉搜索树

### 树

* 链表是特殊化的树（1or2next）；树是特殊的图（有无环）

```python
class TreeNode:
    def __init__(self, val):
        self.val = value
        self.left, self.right = None, None
```

### 二叉树遍历

> [二叉树demo](https://visualgo.net/zh/bst)

前序、中序、后序（根的位置）
二叉搜索树查找效率高 中序遍历 升序

排列组合相关

#### 递归代码模版

```python
def recursion(level, param1, param2, ...):
    # recursion terminator
    if level > MAX_LEVEL:
	   process_result
	   return

    # process logic in current level
    process(level, data...)

    # drill down
    self.recursion(level + 1, p1, ...)

    # reverse the current level status if needed
```

```java
public void recur(int level, int param) {

  // terminator
  if (level > MAX_LEVEL) {
    // process result
    return;
  }

  // process current logic
  process(level, param);

  // drill down
  recur( level: level + 1, newParam);

  // restore current status

}
```

## 深度优先搜索DFS、广度优先搜索

### 深度优先搜索 DFS

```python
# 递归写法
visited = set()
def dfs(node, visited):
  if node in visited: # terminator
  	# already visited
  	return

  visited.add(node)

	# process current node here.
	...
	for next_node in node.children():
		if not next_node in visited:
			dfs(next_node, visited)

# 非递归写法
def DFS(self, tree):

	if tree.root is None:
		return []

	visited, stack = [], [tree.root]

	while stack:
		node = stack.pop()
		visited.add(node)

		process (node)
		nodes = generate_related_nodes(node)
		stack.push(nodes)

	# other processing work
	...
  ```

### 分治 回溯

```python
def divide_conquer(problem, param1, param2, ...):
  # recursion terminator
  if problem is None:
	print_result
	return

  # prepare data
  data = prepare_data(problem)
  subproblems = split_problem(problem, data)

  # conquer subproblems
  subresult1 = self.divide_conquer(subproblems[0], p1, ...)
  subresult2 = self.divide_conquer(subproblems[1], p1, ...)
  subresult3 = self.divide_conquer(subproblems[2], p1, ...)
  …

  # process and generate the final result
  result = process_result(subresult1, subresult2, subresult3, …)

  # revert the current level states
```

### 广度优先遍历

队列实现，python用数组or （connection）deque、Java用链表or deque

  ```python
  def BFS(graph, start, end):

  	queue = []
  	queue.append([start])
  	visited.add(start)

  	while queue:
  		node = queue.pop()
  		visited.add(node)

  		process(node)
  		nodes = generate_related_nodes(node)
  		queue.push(nodes)

  	# other processing work
  	...
  ```

## 贪心算法 greedy

选择当下最好的选择从而希望达到全局最优。
贪心算法与动态规划的不同在于做出选择后不能回退。而动态规划保存以前的结果，并根据以前的结果对当前进行选择，有回退。

最优问题，最小生成树、哈夫曼编码

从前往后、从后往前、证明可达最优

## 二分查找

### 前提

1.单调性
2.上下界
3.索引

```python
# 假设升序
left, right = 0, len(array) - 1
while left <= right:
	  mid = (left + right) / 2  
    # mid = left + (left - right) / 2
	  if array[mid] == target:
		    # find the target!!
		    break or return result
	  elif array[mid] < target:
		    left = mid + 1
	  else:
		    right = mid - 1
```

## 动态规划

simplifying a complicated problem by breaking it down into simpler sub-problems in a recursive manner

> [wiki](https://en.wikipedia.org/wiki/Dynamic_programming)
[MIT动态规划](https://www.bilibili.com/video/av53233912?from=search&seid=2847395688604491997)

分治+最优子结构
自底向上递推

* 动态规划和递归或者分治没有本质的区别
* 共性：找到重复子问题
* 差异：最优子结构、中途淘汰次优解

步骤：
a.重复性（分治）
b.定义状态数组
c.DP方程

[一个方法](https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/solution/yi-ge-fang-fa-tuan-mie-6-dao-gu-piao-wen-ti-by-l-3/)解决stock六个问题

## 字典树和并查集

### 字典树（trie树）
eg.词频搜索
![trie](https://katherinaxxx.github.io/images/post/algorithm1/trie.jpg#width-full){:height="90%" width="90%"}

多叉树
节点上可以存别的信心

基本性质：
* 节点本身不存完整单词
* 从根节点到某一节点连起来，得到字符串
* 每个节点的所有子节点路径代表的字符不相同

![triecon](https://katherinaxxx.github.io/images/post/algorithm1/triecon.jpg#width-full){:height="90%" width="90%"}

空间换时间 词多长查几次

[实现trie](https://leetcode-cn.com/problems/implement-trie-prefix-tree/solution/)

```python
class Trie(object):

	def __init__(self):
		self.root = {}
		self.end_of_word = "#"

	def insert(self, word):
		node = self.root
		for char in word:
			node = node.setdefault(char, {}) # important
		node[self.end_of_word] = self.end_of_word

	def search(self, word):
		node = self.root
		for char in word:
			if char not in node:
				return False
			node = node[char]
		return self.end_of_word in node

	def startsWith(self, prefix):
		node = self.root
		for char in prefix:
			if char not in node:
				return False
			node = node[char]
		return True

```
### 并查集

**适用范围** 组团、配对、判断俩元素是否在一个集合

![bcj](https://katherinaxxx.github.io/images/post/algorithm1/bingchaji.jpg#width-full){:height="90%" width="90%"}

```python
# 初始化 p[i] = i
def init(p):
	# for i = 0 .. n: p[i] = i;
	p = [i for i in range(n)]

def union(self, p, i, j):
	p1 = self.parent(p, i)
	p2 = self.parent(p, j)
	p[p1] = p2

def parent(self, p, i):
	root = i
	while p[root] != root:
		root = p[root]
	while p[i] != i: # 路径压缩 可以不要 但是这个增加了查找速度
		x = i; i = p[i]; p[x] = root
	return root

```

```java
class UnionFind {
	private int count = 0;
	private int[] parent;
	public UnionFind(int n) {
		count = n;
		parent = new int[n];
		for (int i = 0; i < n; i++) {
			parent[i] = i;
		}
	}
	public int find(int p) {
		while (p != parent[p]) {
			parent[p] = parent[parent[p]];
			p = parent[p];
		}
		return p;
	}
	public void union(int p, int q) {
		int rootP = find(p);
		int rootQ = find(q);
		if (rootP == rootQ) return;
		parent[rootP] = rootQ;
		count--;
	}
}
```
## 高级搜索
[AlphaZero](https://nikcheerla.github.io/deeplearningschool/2018/01/01/AlphaZero-Explained/)

三个思路：剪枝、双向BFS、启发式搜索

### 剪枝

leetcode 数独

### 双向BFS

对比两个集合，头和尾，哪个元素少，就让谁当头（交换位置）

leetcode 单词接龙

### 启发式搜索

## 红黑树和AVL树
